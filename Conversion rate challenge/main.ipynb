{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEDHA-Projet-4b-Convertion_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"./img/img.png\" alt=\"DSW LOGO\" width=\"250px\" style=\"margin-left: 0px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Description du d√©fi üö¥üö¥\n",
    "Ce projet fais office de comp√©tition de machine learning similaire √† celles sur Kaggle, au cours duquel les performances des mod√®les sont stock√©es sur un tableau de classement.\n",
    "Les participants travaillent avec deux fichiers : `data_train.csv`, contenant des donn√©es d'entra√Ænement, et `data_test.csv`, avec des donn√©es pour les pr√©dictions.\n",
    "\n",
    "#### Description de l'entreprise üìá\n",
    "[www.datascienceweekly.org](http://www.datascienceweekly.org) cherche √† comprendre le comportement des utilisateurs sur leur site Web pour pr√©dire les abonnements √† la newsletter. La comp√©tition implique de construire un mod√®le pour pr√©dire les conversions, en utilisant des donn√©es de trafic Web open source. La m√©trique d'√©valuation est le score f1.\n",
    "\n",
    "#### Objectifs üéØ\n",
    "- **Partie 1 :** EDA, pr√©traitement et entra√Ænement du mod√®le de base.\n",
    "- **Partie 2 :** Am√©liorer le score f1 du mod√®le avec du feature engineering.\n",
    "- **Partie 3 :** Faire des pr√©dictions sur `data_test.csv` et les soumettre au tableau de classement.\n",
    "- **Partie 4 :** Analyser les param√®tres du meilleur mod√®le et recommander des am√©liorations pour augmenter le taux de conversion.\n",
    "\n",
    "#### Livrable üì¨\n",
    "- Figures d'EDA.\n",
    "- Mod√®le entra√Æn√© pour la pr√©diction des conversions.\n",
    "- Soumission au tableau de classement.\n",
    "- Analyse des param√®tres du meilleur mod√®le avec des recommandations exploitables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 - Load & Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "0.1 - Import libraries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier,VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score,f1_score, ConfusionMatrixDisplay, RocCurveDisplay, mean_absolute_error)\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "0.2 - Read File and Clean\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def describe_df(df):\n",
    "    print('number of rows:',len(df))\n",
    "    print('Display of dataset:')\n",
    "    display(df.head())\n",
    "    print('Basic statistics:')\n",
    "    display(df.describe(include=\"all\"))\n",
    "    print('Pourcentage of missing values:')\n",
    "    display(df.isnull().sum()/len(df)*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "source": [
    "data = pd.read_csv('conversion_data_train.csv')\n",
    "describe_df(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons un jeu de donn√©e de 284 500 lignes avant pr√©processing.\n",
    "\n",
    "`features`\n",
    "- **country** : Pays d'origine de l'utilisateur.\n",
    "- **age** : √Çge de l'utilisateur.\n",
    "- **new_user** : Indique si l'utilisateur est un nouvel utilisateur ou non.\n",
    "- **total_pages_visited** : Nombre total de pages visit√©es par l'utilisateur.\n",
    "\n",
    "`Target`\n",
    "- **converted** : Indique si l'utilisateur a converti (1) ou non (0).\n",
    "\n",
    "`Statistiques des caract√©ristiques :`\n",
    "  - **country** : 4 pays uniques, US √©tant le plus fr√©quent.\n",
    "  - **age** : Moyenne d'√¢ge de 30.56 ans, avec un √©cart type de 8.27 ans.\n",
    "  - **new_user** : 68.55% des utilisateurs sont de nouveaux utilisateurs.\n",
    "  - **source** : SEO, ADS, Direct. Seo √©tant la plus fr√©quente.\n",
    "  - **total_pages_visited** : Moyenne de 4.87 pages visit√©es, avec un √©cart type de 3.34.\n",
    "  \n",
    "`Statistiques de la variable cible :`\n",
    "  - **converted** : Taux de conversion moyen de 3.23%.\n",
    "\n",
    "Le jeu de donn√©e ne poss√®de aucune donn√©e manquantes, c'est un point important pour la mise en place de pipeline par la suite. Cependant, il est important de noter que nous sommes dans une situation d√©s√©quilibre de classes, aussi appel√© imbalanced dataset. Autrement dit, la classe convertie est nettement moins repr√©sent√©e que la convertie.\n",
    "\n",
    "Il est crucial de prendre en compte ce d√©s√©quilibre lors de la mod√©lisation, car les mod√®les de machine learning peuvent avoir tendance √† privil√©gier la classe majoritaire et √† ne pas bien g√©n√©raliser la classe minoritaire. Cela peut conduire √† des pr√©dictions biais√©es et peu pr√©cises pour la classe sous-repr√©sent√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "0.3 - Explore dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target = 'converted'\n",
    "\n",
    "num_features = [c for c in data.columns if c != target]\n",
    "cat_order = {\n",
    "    'converted': [0,1]\n",
    "}\n",
    "\n",
    "def display_distribution(c):\n",
    "    fig = px.histogram(data, c, color = target, facet_row = target, histnorm = 'probability')\n",
    "    fig.update_layout(width=700,height=500)\n",
    "    fig.update_layout(bargap=0.1)\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display_distribution(num_features[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La majorit√© des visiteurs sont situ√©s aux US et UK, il est tr√®s probable les fondateurs du site soit anglophones. Du moins que le site ne soit pas destin√© ou adapt√© √† un public chinois. En effet, les pays europ√©ens et US semblent avoir des meilleurs conversions qu'en Chine. Pour quelles raisons ? Une hypoth√®se serait la barri√®re de la langue."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display_distribution(num_features[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme remarqu√© sur le descriptif du dataset plus haut, on observe des valeurs d'age extr√™mes (>100 ans) et peu represent√©e, sur 280 000 valeurs on peut n√©gliger leur influence et les conserver."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display_distribution(num_features[3])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La majorit√© des visiteurs, qu'ils convertissent ou non, arrivent principalement gr√¢ce au r√©f√©rencement naturel (SEO). Il est logique que la publicit√© attire plus de visiteurs sur le site que la recherche directe de l'URL par l'utilisateur. Cependant, le fait que la publicit√© g√©n√®re moins de trafic que le r√©f√©rencement naturel sugg√®re que soit la strat√©gie publicitaire pourrait √™tre am√©lior√©e, soit que leur travail de r√©f√©rencement naturel est particuli√®rement efficace."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display_distribution(num_features[4])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On devine une tendance d'augmentation de la conversion face au nombre de visite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "1.1 - Score Log Class\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ScoreLog:\n",
    "    def __init__(self, save_score):\n",
    "        self.save_score = save_score\n",
    "        self.load_from_csv()\n",
    "\n",
    "    def load_from_csv(self):\n",
    "        if os.path.exists(self.save_score):\n",
    "            self.df = pd.read_csv(self.save_score)\n",
    "        else:\n",
    "            self.df = pd.DataFrame(columns=[\"len_data\", \"model_name\", \"features_list\", \"f1_score_train\", \"f1_score_test\", \"hyperparameters\", \"datetime\",\"test_size_var\", \"random_state_var\"])\n",
    "\n",
    "    def log_score(self, len_data, model_name, features_list, f1_score_train, f1_score_test, hyperparameters, test_size_var, random_state_var):\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        new_row = {\"len_data\": len_data, \"model_name\": model_name, \"features_list\": features_list, \"f1_score_train\": f1_score_train, \"f1_score_test\": f1_score_test, \"hyperparameters\": hyperparameters, \"test_size_var\": test_size_var, \"random_state_var\": random_state_var, \"datetime\": now}\n",
    "        self.df = pd.concat([self.df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        self.save_to_csv()\n",
    "\n",
    "    def save_to_csv(self):\n",
    "        self.df.to_csv(self.save_score, index=False)\n",
    "\n",
    "    def get_best_score_test(self, model_name=None):\n",
    "        if model_name:\n",
    "            filtered_df = self.df[self.df['model_name'] == model_name]\n",
    "            if filtered_df.empty:\n",
    "                return None  \n",
    "            best_score_row = filtered_df.loc[filtered_df['f1_score_test'].idxmax()]\n",
    "        else:\n",
    "            best_score_row = self.df.loc[self.df['f1_score_test'].idxmax()]\n",
    "        return best_score_row\n",
    "\n",
    "    def get_best_score_train(self, model_name=None):\n",
    "        if model_name:\n",
    "            filtered_df = self.df[self.df['model_name'] == model_name]\n",
    "            if filtered_df.empty:\n",
    "                return None \n",
    "            best_score_row = filtered_df.loc[filtered_df['f1_score_train'].idxmax()]\n",
    "        else:\n",
    "            best_score_row = self.df.loc[self.df['f1_score_train'].idxmax()]\n",
    "        return best_score_row\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "1.2 - F1 score class\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class F1ScoreClassifier:\n",
    "    def __init__(self, classifier, classifier_name, X_train, X_test, Y_train, Y_test, param_grid={}, cv=3, scoring='f1', verbose=0):\n",
    "        self.classifier = classifier\n",
    "        self.classifier_name = classifier_name\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.verbose = verbose\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.f1_score_train = None\n",
    "        self.f1_score_test = None\n",
    "        self.cv_f1_scores = None \n",
    "    \n",
    "    def find_best_params(self):\n",
    "        gridsearch = GridSearchCV(self.classifier, param_grid=self.param_grid, cv=self.cv, scoring=self.scoring, verbose=self.verbose)\n",
    "        gridsearch.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "        self.best_params_ = gridsearch.best_params_\n",
    "        self.best_score_ = gridsearch.best_score_\n",
    "        self.best_estimator_ = gridsearch.best_estimator_\n",
    "    \n",
    "    def evaluate_train_test(self):\n",
    "        Y_train_pred = self.best_estimator_.predict(self.X_train)\n",
    "        Y_test_pred = self.best_estimator_.predict(self.X_test)\n",
    "        self.f1_score_train = f1_score(self.Y_train, Y_train_pred)\n",
    "        self.f1_score_test = f1_score(self.Y_test, Y_test_pred)\n",
    "        \n",
    "        print(f\"{self.classifier_name} F1-score on train set: {self.f1_score_train}\")\n",
    "        print(f\"{self.classifier_name} F1-score on test set: {self.f1_score_test}\")\n",
    "    \n",
    "    def cross_validate(self):\n",
    "        cv_scores = cross_val_score(self.best_estimator_, self.X_train, self.Y_train, cv=self.cv, scoring=self.scoring)\n",
    "        self.cv_f1_scores = cv_scores\n",
    "        # print(f\"{self.classifier_name} Cross-validated F1 scores:\", cv_scores)\n",
    "        print(f\"\\n{self.classifier_name} Cross-validated F1 score: {cv_scores.mean()}\\n\")\n",
    "\n",
    "    def plot_confusion_matrix(self, X, Y, title):\n",
    "        _, ax = plt.subplots()\n",
    "        ax.set(title=title)\n",
    "        ConfusionMatrixDisplay.from_estimator(self.best_estimator_, X, Y, ax=ax)\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curve(self, X, Y, title): \n",
    "        _, ax = plt.subplots()\n",
    "        ax.set(title=title)\n",
    "        RocCurveDisplay.from_estimator(self.best_estimator_, X, Y, ax=ax)\n",
    "        plt.show()\n",
    "\n",
    "    def order_hyperparameters(self):\n",
    "        converted_params = {param: float(value) if isinstance(value, (int, float, str)) else value for param, value in self.best_params_.items()}\n",
    "        self.ordered_hyperparameters = sorted(converted_params.items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 50px; >\n",
    "\n",
    "Pour la suite du projet, deux classes ont √©t√© cr√©√©es. La premi√®re classe stocke des informations sur chaque entra√Ænement de mod√®le afin de constituer un historique et d'identifier les hyperparam√®tres susceptibles d'am√©liorer le `f1-score`. La seconde classe vise √† fluidifier le code, √©viter les r√©p√©titions et acc√©der notamment en ce qui concerne l'utilisation de GridSearch (outil permettant de trouver les meilleurs hyperparam√®tres), acc√®s aux visualisations des r√©sultats des mod√®les.\n",
    "\n",
    "Bien qu'il aurait √©t√© possible de cr√©er une seule classe pour ces fonctionnalit√©s, j'ai pr√©f√©r√© les s√©parer pour √©viter de cr√©er une classe trop g√©n√©raliste.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 50px; >\n",
    "<br>\n",
    "Rappel\n",
    "\n",
    "\n",
    "<span style=\"font-size: 14px\">\n",
    "\n",
    "\n",
    "Le F1-score est calcul√© √† partir des valeurs de True Positive (TP), False Positive (FP) et False Negative (FN).\n",
    "\n",
    "- <strong>True Positive (TP)</strong> : Le nombre d'√©chantillons positifs correctement class√©s.\n",
    "- <strong>False Positive (FP)</strong> : Le nombre d'√©chantillons n√©gatifs incorrectement class√©s comme positifs.\n",
    "- <strong>False Negative (FN)</strong> : Le nombre d'√©chantillons positifs incorrectement class√©s comme n√©gatifs.\n",
    "\n",
    "La pr√©cision (precision) est d√©finie comme le rapport entre TP et la somme de TP et FP :\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "Le rappel (recall) est d√©fini comme le rapport entre TP et la somme de TP et FN :\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "Le F1-score est la moyenne harmonique de la pr√©cision et du rappel, calcul√©e comme suit :\n",
    "\n",
    "$$ F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} $$\n",
    "\n",
    "Le F1-score prend en compte √† la fois la pr√©cision et le rappel, ce qui en fait une mesure utile pour √©valuer la performance d'un mod√®le de classification, surtout lorsque les classes sont d√©s√©quilibr√©es.\n",
    "\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "1.3 - Preprocessing model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nous allons faire une pipeline valable pour tout les mod√®les de classification en fonction des features initiales. Nous distinguons les variables num√©riques et cat√©gorielles. Comprenant dans ce premier mod√®le:\n",
    "- target: converted\n",
    "- numerique: age, total_pages_visited\n",
    "- cat√©gorielle: country, source, new_user\n",
    "\n",
    "Nous mettons en place un jeu de test repr√©sentant 20% des donn√©es, avec une pipeline sans features engineering sur les colonnes dans un premier temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "categorical_features = ['country', 'source', 'new_user']\n",
    "numeric_features = ['age', 'total_pages_visited']\n",
    "\n",
    "features_list = categorical_features+numeric_features\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = data[features_list]\n",
    "Y = data[target]\n",
    "\n",
    "test_size_var=0.2\n",
    "random_state_var = 42\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size_var, random_state=random_state_var, stratify=Y)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "score_logger = ScoreLog('save_score_challenge.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "1.4 - Feature eng LOG , POLY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une pipeline avec du features engineering sur les colonnes est potentiellement utilisable. Pour am√©liorer le code par la suite il sera possible de le rendre plus mal√©able en offrant la possibilit√© de choisir la pipeline."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "active = False\n",
    "if active:\n",
    "    from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size_var, random_state=random_state_var, stratify=Y)\n",
    "\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "    poly_transformer = PolynomialFeatures(degree=2)\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('poly', poly_transformer, numeric_features),\n",
    "            ('log', log_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "\n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    X_test = pipeline.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.1 - First Basic Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 50px;\">\n",
    "Dans un premier temps nous allons faire tourner chaque mod√®le de classification afin d'avoir un premier aper√ßu des performances de chacun, et de voir vers lesquels s'orienter.</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "classifiers = [\n",
    "    (LogisticRegression(), 'LogisticRegression'),\n",
    "    (RandomForestClassifier(), 'RandomForestClassifier'),\n",
    "    (SVC(), 'SVC'),\n",
    "    (AdaBoostClassifier(),'AdaBoostClassifier'),\n",
    "    (XGBClassifier(),'XGBRegressorClassifier'),\n",
    "    (GradientBoostingClassifier(),'GradientBoostingClassifier'),\n",
    "]\n",
    "active = False\n",
    "# active = True\n",
    "\n",
    "if active:\n",
    "    for classifier, classifier_name in classifiers:\n",
    "        cls = F1ScoreClassifier(classifier, classifier_name, X_train, X_test, Y_train, Y_test, param_grid={})\n",
    "        cls.find_best_params() \n",
    "        cls.evaluate_train_test()  \n",
    "        score_logger.log_score(len_data=len(data), model_name=cls.classifier_name, features_list=features_list, f1_score_train=cls.f1_score_train, f1_score_test=cls.f1_score_test, hyperparameters=cls.best_params_,test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "        cls.cross_validate()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 50px;\">\n",
    "\n",
    "On peut se rendre compte que la regression logistique, le xgboost et le gradientboost semblent √™tre les mod√®les les plus aptes √† pr√©senter de bons r√©sultats sans overfitter comme pourrait le faire le d√©cision tree.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Model                       | Train                | Test                 | Cross-Val            |\n",
    "|-----------------------------|----------------------|----------------------|----------------------|\n",
    "| LogisticRegression         | 0.7617969044922612   | 0.7678300455235205   | 0.761317898096414    |\n",
    "| GradientBoostingClassifier | 0.7603867653724128   | 0.76381299332119     | 0.7580431606943927   |\n",
    "| XGBRegressorClassifier     | 0.7711985554134376   | 0.761384335154827    | 0.754029798257489    |\n",
    "| AdaBoostClassifier         | 0.7484605911330049   | 0.750465549348231    | 0.7486040108067217   |\n",
    "| SVC                        | 0.7515009746588694   | 0.7499213589178987   | 0.7487032123178571   |\n",
    "| RandomForestClassifier     | 0.8044642857142857   | 0.7427039904705182   | 0.7312412111296887   |\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"margin-left: 50px;\">\n",
    "D√©sormais nous allons √©tudier chacun des mod√®les et en tirer les meilleurs r√©sulats possible. M√™me si un mod√®le pr√©sente de moins r√©sultats en premi√®re approche il pourrait √™tre utile pour un futur voting ou stacking.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.2 - Logistic Classification\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reg_logistic_regression = LogisticRegression()\n",
    "\n",
    "params_lr = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [26903.536173488137],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter':[300],\n",
    "}\n",
    "\n",
    "\n",
    "cls_lr = F1ScoreClassifier(reg_logistic_regression, 'LogisticRegression', X_train, X_test, Y_train, Y_test, param_grid=params_lr, cv=5)\n",
    "cls_lr.find_best_params()\n",
    "cls_lr.evaluate_train_test()\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_lr.classifier_name, features_list=features_list, f1_score_train=cls_lr.f1_score_train, f1_score_test=cls_lr.f1_score_test, hyperparameters=cls_lr.best_params_, test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_lr.cross_validate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# preprocessor.get_feature_names_out()\n",
    "cls_lr.plot_confusion_matrix(cls_lr.X_train, cls_lr.Y_train, \"Confusion Matrix on Train set\")\n",
    "cls_lr.plot_confusion_matrix(cls_lr.X_test, cls_lr.Y_test, \"Confusion Matrix on Test set\")\n",
    "\n",
    "cls_lr.plot_roc_curve(cls_lr.X_train, cls_lr.Y_train, \"ROC Curve on Train set\")\n",
    "cls_lr.plot_roc_curve(cls_lr.X_test, cls_lr.Y_test, \"ROC Curve on Test set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.3 - Random Forest\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reg_random_forest = RandomForestClassifier()\n",
    "\n",
    "params_rf = {\n",
    "    'max_depth': [10],\n",
    "    'min_samples_leaf': [10],\n",
    "    'min_samples_split': [4],\n",
    "    'n_estimators': [100],\n",
    "    'random_state':[42]\n",
    "}\n",
    "\n",
    "cls_rf = F1ScoreClassifier(reg_random_forest, 'RandomForestClassifier', X_train, X_test, Y_train, Y_test, param_grid=params_rf, cv=5)\n",
    "cls_rf.find_best_params()\n",
    "cls_rf.evaluate_train_test()\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_rf.classifier_name, features_list=features_list, f1_score_train=cls_rf.f1_score_train, f1_score_test=cls_rf.f1_score_test, hyperparameters=cls_rf.best_params_, test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_rf.cross_validate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_rf.plot_confusion_matrix(cls_rf.X_train, cls_rf.Y_train, \"Confusion Matrix on Train set\")\n",
    "cls_rf.plot_confusion_matrix(cls_rf.X_test, cls_rf.Y_test, \"Confusion Matrix on Test set\")\n",
    "\n",
    "cls_rf.plot_roc_curve(cls_rf.X_train, cls_rf.Y_train, \"ROC Curve on Train set\")\n",
    "cls_rf.plot_roc_curve(cls_rf.X_test, cls_rf.Y_test, \"ROC Curve on Test set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.4 - SVM\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reg_svc = SVC()\n",
    "\n",
    "# params_svc = {\n",
    "#     'C': [0.1, 1],\n",
    "#     'kernel': ['rbf'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "\n",
    "params_svc = {\n",
    "    'C': [3],\n",
    "}\n",
    "\n",
    "cls_svc = F1ScoreClassifier(reg_svc, 'SVC', X_train, X_test, Y_train, Y_test, param_grid=params_svc, cv=5)\n",
    "cls_svc.find_best_params()\n",
    "cls_svc.evaluate_train_test()\n",
    "\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_svc.classifier_name, features_list=features_list, f1_score_train=cls_svc.f1_score_train, f1_score_test=cls_svc.f1_score_test, hyperparameters=cls_svc.best_params_,test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_svc.cross_validate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.5 - XGBoost\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "xgboost = XGBClassifier()\n",
    "\n",
    "\n",
    "params = {\n",
    "    'booster': ['gblinear'],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.3],\n",
    "    'eta': [0.2],\n",
    "    'n_estimators': [800],\n",
    "    'scale_pos_weight': [1.84289]\n",
    "}\n",
    "\n",
    "# params = {}\n",
    "\n",
    "cls_xgb = F1ScoreClassifier(xgboost, 'XGBClassifier', X_train, X_test, Y_train, Y_test, param_grid=params,scoring = 'f1', cv=5)\n",
    "cls_xgb.find_best_params()\n",
    "cls_xgb.evaluate_train_test()\n",
    "\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_xgb.classifier_name, features_list=features_list, f1_score_train=cls_xgb.f1_score_train, f1_score_test=cls_xgb.f1_score_test, hyperparameters=cls_xgb.best_params_,test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_xgb.cross_validate()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_xgb.plot_confusion_matrix(cls_xgb.X_train, cls_xgb.Y_train, \"Confusion Matrix on Train set\")\n",
    "cls_xgb.plot_confusion_matrix(cls_xgb.X_test, cls_xgb.Y_test, \"Confusion Matrix on Test set\")\n",
    "\n",
    "cls_xgb.plot_roc_curve(cls_xgb.X_train, cls_xgb.Y_train, \"ROC Curve on Train set\")\n",
    "cls_xgb.plot_roc_curve(cls_xgb.X_test, cls_xgb.Y_test, \"ROC Curve on Test set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.6 - AdaBoost\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "adaboost_dt = AdaBoostClassifier(estimator=decision_tree)\n",
    "\n",
    "params = {\n",
    "    'estimator__max_depth': [4],\n",
    "    'estimator__min_samples_leaf': [2],\n",
    "    'estimator__min_samples_split': [4],\n",
    "    'n_estimators': [8]\n",
    "}\n",
    "# params={}\n",
    "cls_ada = F1ScoreClassifier(adaboost_dt, 'AdaBoostClassifier', X_train, X_test, Y_train, Y_test, param_grid=params, cv=5)\n",
    "cls_ada.find_best_params()\n",
    "cls_ada.evaluate_train_test()\n",
    "\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_ada.classifier_name, features_list=features_list, f1_score_train=cls_ada.f1_score_train, f1_score_test=cls_ada.f1_score_test, hyperparameters=cls_ada.best_params_,test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_ada.cross_validate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "2.7 - GradientBoosting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "gradientboost = GradientBoostingClassifier()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [8],\n",
    "    'min_samples_leaf': [10],\n",
    "    'min_samples_split': [8],\n",
    "    'n_estimators': [48]\n",
    "}\n",
    "\n",
    "cls_gb = F1ScoreClassifier(gradientboost, 'GradientBoostingClassifier', X_train, X_test, Y_train, Y_test, param_grid=params, cv=5)\n",
    "cls_gb.find_best_params()\n",
    "cls_gb.evaluate_train_test()\n",
    "\n",
    "score_logger.log_score(len_data=len(data), model_name=cls_gb.classifier_name, features_list=features_list, f1_score_train=cls_gb.f1_score_train, f1_score_test=cls_gb.f1_score_test, hyperparameters=cls_gb.best_params_,test_size_var=test_size_var, random_state_var=random_state_var)\n",
    "cls_gb.cross_validate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_xgb.plot_confusion_matrix(cls_xgb.X_train, cls_xgb.Y_train, \"Confusion Matrix on Train set\")\n",
    "cls_xgb.plot_confusion_matrix(cls_xgb.X_test, cls_xgb.Y_test, \"Confusion Matrix on Test set\")\n",
    "\n",
    "cls_xgb.plot_roc_curve(cls_xgb.X_train, cls_xgb.Y_train, \"ROC Curve on Train set\")\n",
    "cls_xgb.plot_roc_curve(cls_xgb.X_test, cls_xgb.Y_test, \"ROC Curve on Test set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - Voting & Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "3.1 - Voting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_lr_best = LogisticRegression(penalty='l1', C=26903.536173488137, solver='saga', max_iter=300)\n",
    "cls_xgb_best = XGBClassifier(booster='gblinear', objective = 'binary:logistic',learning_rate = 0.3,eta = 0.2,n_estimators=800,scale_pos_weight =1.84289)\n",
    "cls_random_forest_best = RandomForestClassifier(max_depth=10, min_samples_leaf=10, min_samples_split=4, n_estimators=100)\n",
    "cls_gradientboost_best = GradientBoostingClassifier(max_depth = 8,min_samples_leaf=10,min_samples_split = 8,n_estimators = 48)\n",
    "cls_adaboost_dt_best = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, min_samples_split=4),n_estimators=8)\n",
    "cls_svc_best = SVC()\n",
    "\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[(\"logistic\", cls_lr_best), (\"xgboost_best\", cls_xgb_best)],\n",
    "    # voting=\"hard\",\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "voting.fit(X_train, Y_train)\n",
    "y_pred_train = voting.predict(X_train)\n",
    "y_pred_test = voting.predict(X_test)\n",
    "\n",
    "f1_train = f1_score(Y_train, y_pred_train)\n",
    "f1_test = f1_score(Y_test, y_pred_test)\n",
    "\n",
    "print(\"F1 score on training set:\", f1_train)\n",
    "print(\"F1 score on test set:\", f1_test)\n",
    "\n",
    "cv_scores = np.mean(cross_val_score(voting, X_train, Y_train, cv=5, scoring='f1'))\n",
    "print(np.mean(cv_scores))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "3.2 - Stacking\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "active = False\n",
    "active = True\n",
    "\n",
    "if active:\n",
    "    cls_lr_best = LogisticRegression(penalty='l1', C=26903.536173488137, solver='saga', max_iter=300)\n",
    "    cls_xgb_best = XGBClassifier(booster='gblinear', objective = 'binary:logistic',learning_rate = 0.3,eta = 0.2,n_estimators=800,scale_pos_weight =1.84289)\n",
    "\n",
    "    stacking = StackingClassifier(\n",
    "        estimators=[(\"reg_logistic_regression_best\", cls_lr_best), (\"xgboost_best\", cls_xgb_best)],\n",
    "    )\n",
    "\n",
    "    preds = stacking.fit_transform(X_train, Y_train)\n",
    "    predictions = pd.DataFrame(preds, columns=stacking.named_estimators_.keys())\n",
    "\n",
    "\n",
    "    stacking.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred_train = stacking.predict(X_train)\n",
    "    y_pred_test = stacking.predict(X_test)\n",
    "\n",
    "    f1_train = f1_score(Y_train, y_pred_train)\n",
    "    f1_test = f1_score(Y_test, y_pred_test)\n",
    "\n",
    "    print(\"F1 score on training set:\", f1_train)\n",
    "    print(\"F1 score on test set:\", f1_test)\n",
    "\n",
    "    cv_scores = np.mean(cross_val_score(stacking, X_train, Y_train, cv=3, scoring='f1'))\n",
    "    print(np.mean(cv_scores))\n",
    "\n",
    "    corr_matrix = predictions.corr().round(2)\n",
    "    import plotly.figure_factory as ff\n",
    "\n",
    "    fig = ff.create_annotated_heatmap(corr_matrix.values, x=corr_matrix.columns.tolist(), y=corr_matrix.index.tolist())\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "3.3 - Voting+Stacking (Frankenstein)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_lr_best = LogisticRegression(penalty='l1', C=26903.536173488137, solver='saga', max_iter=300)\n",
    "cls_xgb_best = XGBClassifier(booster='gblinear', objective = 'binary:logistic',learning_rate = 0.3,eta = 0.2,n_estimators=800,scale_pos_weight =1.84289)\n",
    "cls_random_forest_best = RandomForestClassifier(max_depth=10, min_samples_leaf=10, min_samples_split=4, n_estimators=100)\n",
    "cls_gradientboost_best = GradientBoostingClassifier(max_depth = 8,min_samples_leaf=10,min_samples_split = 8,n_estimators = 48)\n",
    "cls_adaboost_dt_best = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, min_samples_split=4),n_estimators=8)\n",
    "cls_svc_best = SVC(probability=True)\n",
    "\n",
    "\n",
    "voting1 = VotingClassifier(\n",
    "    estimators=[(\"cls_adaboost_dt_best\", cls_adaboost_dt_best), (\"cls_svc_best\", cls_svc_best)],   \n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[(\"cls_lr_best\", cls_lr_best), (\"cls_xgb_best\", cls_xgb_best)], \n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[(\"adaboost_svc\", voting1), (\"lr_xgb\", voting2)],\n",
    ")\n",
    "\n",
    "\n",
    "preds = stacking.fit_transform(X_train, Y_train)\n",
    "predictions = pd.DataFrame(preds, columns=stacking.named_estimators_.keys())\n",
    "\n",
    "stacking.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_train = stacking.predict(X_train)\n",
    "y_pred_test = stacking.predict(X_test)\n",
    "\n",
    "f1_train = f1_score(Y_train, y_pred_train)\n",
    "f1_test = f1_score(Y_test, y_pred_test)\n",
    "\n",
    "print(\"F1 score on training set:\", f1_train)\n",
    "print(\"F1 score on test set:\", f1_test)\n",
    "\n",
    "cv_scores = np.mean(cross_val_score(stacking, X_train, Y_train, cv=3, scoring='f1'))\n",
    "print('cv_score',np.mean(cv_scores))\n",
    "\n",
    "corr_matrix = predictions.corr().round(2)\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "fig = ff.create_annotated_heatmap(corr_matrix.values, x=corr_matrix.columns.tolist(), y=corr_matrix.index.tolist())\n",
    "fig.update_layout(width=700)\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Model                                | Train                | Test                 | Cross-Val            |\n",
    "|--------------------------------------|----------------------|----------------------|----------------------|\n",
    "| XGBRegressorClassifier_gs           | 0.7698390677025527   | 0.7722330638416504   | 0.7688006973234403   |\n",
    "| stacking_xgb_lr                     | 0.7689066472938613   | 0.7735354124162052   | 0.7680804298273997   |\n",
    "| voting_xgb_lr                       | 0.7685848715164676   | 0.7750724637681159   | 0.7678745168257773   |\n",
    "| LogisticRegression_gs               | 0.7618832050701675   | 0.7684848484848484   | 0.7620626784328032   |\n",
    "| RandomForestClassifier_gs          | 0.7697651589518991   | 0.7595013681970204   | 0.7567297334531815   |\n",
    "| AdaBoostClassifier_gs               | 0.7632772494513533   | 0.7660818713450293   | 0.7570407079224383   |\n",
    "| GradientBoostingClassifier_gs        | 0.7788937190825963   | 0.760928549894483    | 0.7511303484163259   |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 - Best Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section to look at the best results on test or train f1-score for all models or per model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "4.1 - By Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "name = {\n",
    "    0: 'LogisticRegression',\n",
    "    1: 'RandomForestClassifier',\n",
    "    2: 'SVC',\n",
    "    3: 'AdaBoostClassifier',\n",
    "    4: 'XGBRegressorClassifier',\n",
    "    5: 'GradientBoostingClassifier'\n",
    "}\n",
    "name_nb=3\n",
    "best_score_by_model = score_logger.get_best_score_test(model_name=name_nb)\n",
    "print(f\"Best score for {name.get(name_nb)} model:\", best_score_by_model)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "4.2 - Over all Models\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "f1_score_best = score_logger.get_best_score_test()\n",
    "print(\"Best Score:\")\n",
    "print(f1_score_best)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 - SAVE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section destinate to save a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "5.1 - Save a Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cls_xgb_best = XGBClassifier(booster='gblinear', objective = 'binary:logistic',learning_rate = 0.3,eta = 0.2,n_estimators=800,scale_pos_weight =1.84289)\n",
    "\n",
    "model_name = 'cls_xgb_best'\n",
    "classifier = cls_xgb_best\n",
    "\n",
    "active = False\n",
    "# active = True\n",
    "if active:\n",
    "    X = np.append(X_train,X_test,axis=0)\n",
    "    Y = np.append(Y_train,Y_test)\n",
    "\n",
    "    classifier.fit(X,Y)\n",
    "    data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "    X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "    # X_without_labels = X_without_labels.values\n",
    "    X_without_labels = preprocessor.transform(X_without_labels)\n",
    "\n",
    "    data_pred = {\n",
    "        'converted': classifier.predict(X_without_labels)\n",
    "    }\n",
    "\n",
    "    Y_predictions = pd.DataFrame(columns=['converted'],data=data_pred)\n",
    "    csv_name = f\"conversion_data_test_predictions_AntoineV-model_{model_name}.csv\"\n",
    "    Y_predictions.to_csv(csv_name, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<div style=\"margin-left: 50px; font-size: 20px;\">\n",
    "5.2 - Save \"Best\" Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_name = f1_score_best['model_name']\n",
    "hyperparameters = f1_score_best['hyperparameters']\n",
    "\n",
    "classifier = eval(model_name)(**hyperparameters)\n",
    "\n",
    "active = False\n",
    "# active = True\n",
    "\n",
    "if active:\n",
    "    X = np.append(X_train,X_test,axis=0)\n",
    "    Y = np.append(Y_train,Y_test)\n",
    "\n",
    "    classifier.fit(X,Y)\n",
    "    data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "    X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "    # X_without_labels = X_without_labels.values\n",
    "    X_without_labels = preprocessor.transform(X_without_labels)\n",
    "\n",
    "    data_pred = {\n",
    "        'converted': classifier.predict(X_without_labels)\n",
    "    }\n",
    "\n",
    "    Y_predictions = pd.DataFrame(columns=['converted'],data=data_pred)\n",
    "    csv_name = f\"conversion_data_test_predictions_AntoineV-model_{model_name}_{str(f1_score_best['f1_score_test'])}.csv\"\n",
    "    Y_predictions.to_csv(csv_name, index=False)\n",
    "    print('new best classifier',model_name,f1_score_best)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour r√©sumer ce projet, nous avons entrepris une analyse approfondie des `donn√©es d√©s√©quilibr√©es` (imbalanced data), ce qui a n√©cessit√© une d√©marche m√©thodique pour garantir des r√©sultats fiables et significatifs. Notre objectif principal √©tait de d√©velopper des `mod√®les de machine learning` capables de pr√©dire efficacement une variable cible mal √©quilibr√©e.\n",
    "\n",
    "Dans notre d√©marche, nous avons tout d'abord identifi√© le d√©s√©quilibre des classes dans nos donn√©es et ses implications sur la performance des mod√®les. Ensuite, nous avons s√©lectionn√© plusieurs approches pour traiter ce d√©s√©quilibre, notamment l'utilisation d'une m√©trique d'√©valuation adapt√©e: le F1-score.\n",
    "\n",
    "En ce qui concerne les r√©sultats, plusieurs mod√®les ont d√©montr√© des performances prometteuses. Notamment, le mod√®le `XGBoost` et la `r√©gression logistique` ont affich√© des performances solides. De plus, lorsque nous les avons combin√©s dans un cadre de voting ou de stacking, nous avons observ√© une l√©g√®re am√©lioration des performances (`voting_xgb_lr` et `stacking_xgb_lr`). Ces combinaisons de mod√®les ont permis de capitaliser sur les forces individuelles de chaque algorithme, conduisant ainsi √† des performances globales plus √©lev√©es.\n",
    "\n",
    "\n",
    "En conclusion, ce projet met en lumi√®re l'importance de prendre en compte le d√©s√©quilibre des classes lors de la mod√©lisation des donn√©es. Les approches et les techniques que nous avons explor√©es ont permis d'am√©liorer la performance des mod√®les et de produire des pr√©dictions plus pr√©cises. Cependant, il reste encore des possibilit√©s d'am√©lioration, notamment en explorant davantage de techniques sp√©cifiques aux donn√©es d√©s√©quilibr√©es et en affinant les param√®tres des mod√®les pour obtenir des performances encore meilleures. Des librairies comme `imbalanced-learn` existent et permettent de prendre en charge ces cas d'imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un constat important est le `faible taux de conversion` des acheteurs `chinois`, bien qu'ils repr√©sentent un groupe d√©mographique significatif. La priorit√© principale est donc de conseiller √† l'√©quipe produit de r√©viser la version chinoise du site pour garantir un `contenu adapt√©`: traductions pr√©cises, options de paiement appropri√©es.\n",
    "\n",
    "Etant donn√© que le site r√©ussit √† convertir les acheteurs de moins de `40 ans`, l'√©quipe marketing devrait concentrer ses efforts sur ce groupe √† travers des publicit√©s. Il serait b√©n√©fique de repr√©senter le site (retargeting) aux visiteurs qui ont consult√© de `nombreuses pages` mais n'ont pas encore franchi le pas, car c'est un indicateur positif de `conversion potentielle`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
